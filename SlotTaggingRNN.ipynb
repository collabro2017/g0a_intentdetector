{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "[array([232, 542, 502, 196, 208,  77,  62,  10,  35,  40,  58, 234, 137,\n",
      "        62,  11, 234, 481, 321]), array([554, 194,  50,  66, 208, 379, 502,  69, 358, 496, 321]), array([554, 241, 481,  56, 500, 234, 415, 205, 200, 481,  10,  35, 193,\n",
      "       270, 543]), array([ 99,  24, 208, 466, 502, 367]), array([410, 515, 183, 208, 379, 502, 376, 529,  11, 158]), array([232, 331,  13, 193, 504, 208, 114, 502, 313]), array([554, 252, 353,  23, 241, 534, 358,  13, 193, 208, 107, 502, 128]), array([439, 301, 481, 194, 208, 379, 502, 285,  41, 358, 496]), array([ 32, 194, 208,  77, 502, 543]), array([554, 252, 353, 217, 512, 241,  66, 234, 137])]\n",
      "--------------------------\n",
      "-------------------------\n",
      "['what', 'is', 'the', 'arrival', 'time', 'in', 'san', 'francisco', 'for', 'the', 'DIGITDIGITDIGIT', 'am', 'flight', 'leaving', 'washington']\n",
      "['O', 'O', 'O', 'B-flight_time', 'I-flight_time', 'O', 'B-fromloc.city_name', 'I-fromloc.city_name', 'O', 'O', 'B-depart_time.time', 'I-depart_time.time', 'O', 'O', 'B-fromloc.city_name']\n",
      "------------------------\n",
      "-------------------------\n",
      "--------------------------\n",
      "['what', 'are', 'the', 'nonstop', 'flights', 'from', 'cincinnati', 'to', 'charlotte', 'leaving', 'after', 'noon', 'and', 'arriving', 'before', 'DIGIT', 'pm']\n",
      "['O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import data.load\n",
    "\n",
    "train_set, valid_set, dicts = data.load.atisfull()\n",
    "w2idx, labels2idx = dicts['words2idx'], dicts['labels2idx']\n",
    "#print(w2idx)\n",
    "#print(labels2idx)\n",
    "\n",
    "train_x, _, train_label = train_set\n",
    "val_x, _, val_label = valid_set\n",
    "\n",
    "# Create index to word/label dicts\n",
    "idx2w  = {w2idx[k]:k for k in w2idx}\n",
    "idx2la = {labels2idx[k]:k for k in labels2idx}\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "#print(idx2w)\n",
    "#print(idx2la)\n",
    "\n",
    "\n",
    "print(train_x[0:10])\n",
    "\n",
    "# For conlleval script\n",
    "words_train = [ list(map(lambda x: idx2w[x], w)) for w in train_x]\n",
    "labels_train = [ list(map(lambda x: idx2la[x], y)) for y in train_label]\n",
    "words_val = [ list(map(lambda x: idx2w[x], w)) for w in val_x]\n",
    "labels_val = [ list(map(lambda x: idx2la[x], y)) for y in val_label]\n",
    "\n",
    "n_classes = len(idx2la)\n",
    "n_vocab = len(idx2w)\n",
    "\n",
    "print(\"--------------------------\")\n",
    "print(\"-------------------------\")\n",
    "\n",
    "\n",
    "print(words_train[2])\n",
    "print(labels_train[2])\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"-------------------------\")\n",
    "print(\"--------------------------\")\n",
    "print(words_val[800])\n",
    "print(labels_val[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence : ['i', 'want', 'to', 'fly', 'from', 'boston', 'at', 'DIGITDIGITDIGIT', 'am', 'and', 'arrive', 'in', 'denver', 'at', 'DIGITDIGITDIGITDIGIT', 'in', 'the', 'morning']\n",
      "Encoded form: [232 542 502 196 208  77  62  10  35  40  58 234 137  62  11 234 481 321]\n",
      "\n",
      "It's label : ['O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-depart_time.time', 'I-depart_time.time', 'O', 'O', 'O', 'B-toloc.city_name', 'O', 'B-arrive_time.time', 'O', 'O', 'B-arrive_time.period_of_day']\n",
      "Encoded form: [126 126 126 126 126  48 126  35  99 126 126 126  78 126  14 126 126  12]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Example sentence : {}\".format(words_train[0]))\n",
    "print(\"Encoded form: {}\".format(train_x[0]))\n",
    "print()\n",
    "print(\"It's label : {}\".format(labels_train[0]))\n",
    "print(\"Encoded form: {}\".format(train_label[0]))\n",
    "print(type(words_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jfver\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\jfver\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 5, activation=\"relu\", padding=\"same\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Convolution1D, GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_vocab,100))\n",
    "model.add(Convolution1D(128, 5, border_mode='same', activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(GRU(100,return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
    "model.compile('rmsprop', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "N/A% (0 of 4978) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([232, 542, 502, 196, 208,  77,  62,  10,  35,  40,  58, 234, 137,\n",
      "        62,  11, 234, 481, 321])]\n",
      "127\n",
      "Training epoch 0\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0:1])\n",
    "print(n_classes)\n",
    "\n",
    "import progressbar\n",
    "n_epochs = 30\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print(\"Training epoch {}\".format(i))\n",
    "    \n",
    "    bar = progressbar.ProgressBar(maxval=len(train_x))\n",
    "    for n_batch, sent in bar(enumerate(train_x)):\n",
    "        label = train_label[n_batch]\n",
    "        # Make labels one hot\n",
    "        label = np.eye(n_classes)[label][np.newaxis,:]\n",
    "        # View each sentence as a batch\n",
    "        sent = sent[np.newaxis,:]\n",
    "        \n",
    "        if sent.shape[1] > 1: #ignore 1 word sentences\n",
    "            model.train_on_batch(sent, label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom metrics.accuracy import conlleval\\n\\nlabels_pred_val = []\\n\\nbar = progressbar.ProgressBar(maxval=len(val_x))\\nfor n_batch, sent in bar(enumerate(val_x)):\\n    label = val_label[n_batch]\\n    label = np.eye(n_classes)[label][np.newaxis,:]\\n    sent = sent[np.newaxis,:]\\n\\n    pred = model.predict_on_batch(sent)\\n    pred = np.argmax(pred,-1)[0]\\n    labels_pred_val.append(pred)\\n\\nlabels_pred_val = [ list(map(lambda x: idx2la[x], y))                                     for y in labels_pred_val]\\n# Predictions, Ground Truths, Corresponding Words, Name of the files where the predictions are made.\\ncon_dict = conlleval(labels_pred_val, labels_val, \\n                            words_val, 'measure.txt')\\n\\nprint('Precision = {}, Recall = {}, F1 = {}'.format(\\n            con_dict['r'], con_dict['p'], con_dict['f1']))\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from metrics.accuracy import conlleval\n",
    "\n",
    "labels_pred_val = []\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=len(val_x))\n",
    "for n_batch, sent in bar(enumerate(val_x)):\n",
    "    label = val_label[n_batch]\n",
    "    label = np.eye(n_classes)[label][np.newaxis,:]\n",
    "    sent = sent[np.newaxis,:]\n",
    "\n",
    "    pred = model.predict_on_batch(sent)\n",
    "    pred = np.argmax(pred,-1)[0]\n",
    "    labels_pred_val.append(pred)\n",
    "\n",
    "labels_pred_val = [ list(map(lambda x: idx2la[x], y)) \\\n",
    "                                    for y in labels_pred_val]\n",
    "# Predictions, Ground Truths, Corresponding Words, Name of the files where the predictions are made.\n",
    "con_dict = conlleval(labels_pred_val, labels_val, \n",
    "                            words_val, 'measure.txt')\n",
    "\n",
    "print('Precision = {}, Recall = {}, F1 = {}'.format(\n",
    "            con_dict['r'], con_dict['p'], con_dict['f1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for loading AWS Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
